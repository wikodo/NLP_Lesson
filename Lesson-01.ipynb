{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "from random import choice\n",
    "from random import choice\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher=\"\"\"\n",
    "requirement = 对象 需要 寻找 数量 方法 解决 问题\n",
    "对象 = 你 | 你们 | 他| 她 | 他们\n",
    "需要 = 必须 | 一定要 | 需要\n",
    "寻找 = 找到 | 发现 | 知晓 | 明白\n",
    "数量 = 数字 个\n",
    "数字 = 单个数字 | 数字 单个数字\n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6\n",
    "方法 = 办法 | 方案 | 论据 | 论点\n",
    "解决 = 搞定 | 弄好 | 修理\n",
    "问题 = 难题 | 题目 | 机器 | 车辆\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = \"\"\"\n",
    "answer = 代词 谓语 宾语\n",
    "代词 = 这 | 那\n",
    "谓语 = 简直是 | 真的是 | 必须是\n",
    "宾语 = 小菜一碟 | 难如登天 | 随手拈来\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_grammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(gram_str, split='='):\n",
    "    grammar = {}\n",
    "    for line in gram_str.split('\\n'):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(gram, target):\n",
    "    if target not in gram:\n",
    "        return target\n",
    "    expanded = [generate(gram, t) for t in choice(gram[target])]\n",
    "    return ''.join([e for e in expanded if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(n):\n",
    "    for i in range(n):\n",
    "        yield generate(gram=create_grammar(teacher, split='='), target='requirement'), generate(gram=create_grammar(student, split='='), target='answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('她必须找到6个方案修理机器', '那必须是小菜一碟')\n",
      "('你们必须明白5个方案弄好机器', '那真的是难如登天')\n",
      "('他一定要找到5611个方案修理机器', '这真的是小菜一碟')\n",
      "('他一定要知晓34个方案搞定车辆', '那必须是小菜一碟')\n",
      "('他们一定要明白2个论点修理机器', '那必须是小菜一碟')\n"
     ]
    }
   ],
   "source": [
    "for line in generate_n(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'D:\\\\NLP\\\\material\\\\datasource-master\\\\sqlResult_1558436.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_csv(filename, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = content['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_clean = [''.join(token(str(a))) for a in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\NLP\\\\material\\\\datasource-master\\\\article_9k.txt', 'w') as f:\n",
    "    for a in articles_clean:\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate((open('D:\\\\NLP\\\\material\\\\datasource-master\\\\article_9k.txt'))):\n",
    "    TOKEN += cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word] / len(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability(sentence):\n",
    "    words = cut(sentence)\n",
    "    sentence_pro = 1\n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        probability = prob_2(word, next_)\n",
    "        sentence_pro *= probability\n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(n):\n",
    "    prob_dic = {}\n",
    "    for sen in [generate(gram=create_grammar(teacher, split='='), target='requirement') for i in range(n)]:\n",
    "        prob_dic[sen] = get_probability(sen)\n",
    "    probabilities = [probability for probability in zip(prob_dic.keys(), prob_dic.values())]\n",
    "    prob_sorted = sorted(probabilities, key=lambda x:x[1], reverse=True)\n",
    "    return prob_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "她必须知晓2251个办法弄好难题 1.1633789862471658e-56\n",
      "你必须找到5162个方案修理机器 3.4161173585345166e-49\n",
      "你必须找到46个办法弄好题目 3.3737990601167806e-54\n",
      "他们一定要找到6个论点修理车辆 1.2809712659477205e-50\n",
      "你们一定要找到3个论点弄好难题 1.4055845965831788e-57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('你必须找到5162个方案修理机器', 3.4161173585345166e-49)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfpy3.6] *",
   "language": "python",
   "name": "conda-env-tfpy3.6-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
